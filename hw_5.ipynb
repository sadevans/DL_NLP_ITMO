{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrsfdhFlviDJfqPYyP7FI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sadevans/DL_NLP_ITMO/blob/hw_5/hw_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Домашнее задание 5 - 10 баллов\n",
        "\n",
        "В этом задании вам предстоит дообучить трансформерную модель для задачи классификации с помощью различных техник и сравнить их между собой.\n",
        "\n",
        "Датасет: [dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion)\n",
        "\n",
        "Модель: [google-bert/bert-base-uncased](https://huggingface.co/google-bert/bert-base-uncased) (если хочется, можно заменить на что-то более интересное)\n",
        "\n",
        "1. Скачайте датасет и модель. Измерьте базовые метрики классификации перед началом экспериментов.\n",
        "\n",
        "**NB!** Для всех типов дообучения замерьте :\n",
        "- качество классификации на выходе\n",
        "- время дообучения\n",
        "- количество параметров для обучения\n",
        "- потребление ресурсов (не нужно заморачиваться с профайлингом - можно просто посмотреть в `nvidia-smi` или `torch.cuda.memory_allocated`)\n",
        "\n",
        "2. Обучите модель в режиме full finetuning - **1 балл**\n",
        "3. Обучите модель в режиме linear probing - реализуйте кастомную классификационную голову и обучайте только ее. Не забудьте описать, чем обусловлено устройство головы, как вы пришли к такой архитектуре - **2 балла**\n",
        "4. Обучите модель в режиме PEFT с использованием [prompt tuning или prefix tuning](https://ericwiener.github.io/ai-notes/AI-Notes/Large-Language-Models/Prompt-Tuning-and-Prefix-Tuning). При выборе метода напишите пару слов, почему решили остановиться именно на этом методе - **2 балла**\n",
        "4. Обучите модель в режиме PEFT с использованием LoRA. Попробуйте подобрать оптимальный ранг - `r`, при желании поэкспериментируйте с остальными гиперпараметрами. Опишите, чем обусловлена ваша финальная конфигурация - **2 балла**\n",
        "\n",
        "5. Соберите все результаты отдельных замеров в таблицу и сделайте выводы о вычислительной сложности методов, итоговом качестве и прочих наблюдаемых свойствах моделей - **1 балл**\n"
      ],
      "metadata": {
        "id": "nJ4mgdlqCKST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GlPD0Y6kCIjk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets transformers peft torchmetrics\n",
        "!pip install evaluate\n",
        "!pip install hf_xet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import subprocess\n",
        "import time\n",
        "from random import sample\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from torch import nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics.functional import accuracy\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BertConfig,\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    BertModel,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "\n",
        "sns.set_theme()\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "s8b1RDKBC7R8"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Фикисируем seed"
      ],
      "metadata": {
        "id": "LJhkFSxyC3St"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 42\n",
        "os.environ[\"SEED\"] = str(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDJGQ2tzCKv2",
        "outputId": "733cfada-141e-4f3b-91dd-362c14a54809"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f95085df590>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GEwU4ioEDD8g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Скачиваем датасет и модель"
      ],
      "metadata": {
        "id": "Q0lpiL_DDVX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"dair-ai/emotion\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qLzBZrxDX_A",
        "outputId": "00f9ce6d-ed4e-46f0-d8ae-5de1c04ee29b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### токенизация"
      ],
      "metadata": {
        "id": "F5nI4m5OF5cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZO1M7a6GGCt",
        "outputId": "cb2cc4a9-271b-49be-a5ca-c29ddb4e7943"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
      ],
      "metadata": {
        "id": "tpIzHAVYF_Kd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\", columns=[\"text\", \"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "id": "v9qaQloOF9fg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets['train']['labels'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmOUdXhOJaFE",
        "outputId": "d618d5c1-daa7-4375-ab09-949340df681f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=batch_size, num_workers=8)\n",
        "valid_loader = DataLoader(tokenized_datasets['validation'], shuffle=False, batch_size=batch_size, num_workers=8)\n",
        "test_loader = DataLoader(tokenized_datasets['test'], shuffle=False, batch_size=batch_size, num_workers=8)\n"
      ],
      "metadata": {
        "id": "v6Lr8ffefY0u"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### метрики загружаем"
      ],
      "metadata": {
        "id": "3Av0oHzKFvWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    if isinstance(logits, tuple):\n",
        "        logits = logits[1]\n",
        "\n",
        "    if hasattr(logits, \"numpy\"):\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    predictions = predictions.tolist()\n",
        "    labels = labels.tolist() if hasattr(labels, \"tolist\") else list(labels)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"],\n",
        "        \"f1\": f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"precision\": precision_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"],\n",
        "        \"recall\": recall_metric.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "-dFlLY6dFxlL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### замеряем базовое качество"
      ],
      "metadata": {
        "id": "FgEpeZLQgtp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels=6)\n",
        "base_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DlfNnzAIokB",
        "outputId": "012e4456-9d7f-42fd-b065-9a559574ed05"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./peft/baseline/\",\n",
        "    per_device_eval_batch_size=16,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=base_model,\n",
        "    args=training_args,\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "baseline = trainer.evaluate()\n",
        "print(\"Baseline metrics:\")\n",
        "print('\\n'.join(f\"{key}: {value}\" for key, value in baseline.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "6PZzVbuQGxhh",
        "outputId": "a4631c0b-a157-4f25-a3b5-5570f998fa1b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline metrics:\n",
            "eval_loss: 1.8653087615966797\n",
            "eval_model_preparation_time: 0.0032\n",
            "eval_accuracy: 0.0795\n",
            "eval_f1: 0.024651162790697675\n",
            "eval_precision: 0.013309894525364139\n",
            "eval_recall: 0.16666666666666666\n",
            "eval_runtime: 12.5178\n",
            "eval_samples_per_second: 159.772\n",
            "eval_steps_per_second: 9.986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_results = pd.DataFrame()\n",
        "data_results = {'exp':[], 'accuracy':[], 'f1': [], 'recall':[], 'precision':[], 'time_finetuning':[], 'num_params_finetuning':[], 'resources_used':[]}"
      ],
      "metadata": {
        "id": "SaTWDG6nIg2v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_memory = torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "id": "4WY7AVVMOLZB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_results['exp'].append('baseline')\n",
        "data_results['accuracy'].append(baseline['eval_accuracy'])\n",
        "data_results['f1'].append(baseline['eval_f1'])\n",
        "data_results['recall'].append(baseline['eval_recall'])\n",
        "data_results['precision'].append(baseline['eval_precision'])\n",
        "data_results['time_finetuning'].append(None)\n",
        "data_results['num_params_finetuning'].append(None)\n",
        "data_results['resources_used'].append(None)"
      ],
      "metadata": {
        "id": "mGrcmNWfNeXm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Полный finetuning"
      ],
      "metadata": {
        "id": "TWCYslnjOMaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "5jebv-bpg8zm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=6\n",
        ")\n",
        "model_full_finetune = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaS4dyYhQKOU",
        "outputId": "017d9b8f-a7b6-4ffd-c23d-c291b86d581f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "training_args_full_finetune = TrainingArguments(\n",
        "    output_dir=\"./peft/full_finetuning\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        ")\n",
        "\n",
        "trainer_full_finetune = Trainer(\n",
        "    model=model_full_finetune,\n",
        "    args=training_args_full_finetune,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer_full_finetune.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "_TzeRv-hOODJ",
        "outputId": "92f4dd80-2b7f-4df7-ceb0-d4bb3ef5f8f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaddevans\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250502_102240-tflwq433</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saddevans/huggingface/runs/tflwq433' target=\"_blank\">./peft/full_finetuning</a></strong> to <a href='https://wandb.ai/saddevans/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saddevans/huggingface' target=\"_blank\">https://wandb.ai/saddevans/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saddevans/huggingface/runs/tflwq433' target=\"_blank\">https://wandb.ai/saddevans/huggingface/runs/tflwq433</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 17:09, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.217600</td>\n",
              "      <td>0.181463</td>\n",
              "      <td>0.928500</td>\n",
              "      <td>0.905014</td>\n",
              "      <td>0.896678</td>\n",
              "      <td>0.917800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.113200</td>\n",
              "      <td>0.142525</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>0.920597</td>\n",
              "      <td>0.927169</td>\n",
              "      <td>0.915841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.074300</td>\n",
              "      <td>0.150835</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>0.913122</td>\n",
              "      <td>0.919748</td>\n",
              "      <td>0.908379</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3000, training_loss=0.23817086919148764, metrics={'train_runtime': 1033.1628, 'train_samples_per_second': 46.459, 'train_steps_per_second': 2.904, 'total_flos': 3157446057984000.0, 'train_loss': 0.23817086919148764, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer_full_finetune.predict(tokenized_datasets[\"test\"])\n",
        "full_finetune_results = compute_metrics((test_results.predictions, test_results.label_ids))\n",
        "full_time = time.time() - start_time\n",
        "full_params = sum(p.numel() for p in model_full_finetune.parameters() if p.requires_grad)\n",
        "full_memory = torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "JeLx8SzIaymk",
        "outputId": "959ff070-865b-4cd8-c8c4-ffb3f64eef10"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### качество замеряем"
      ],
      "metadata": {
        "id": "xbnmmP9yVFJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Full finetune metrics:\")\n",
        "print('\\n'.join(f\"{key}: {value}\" for key, value in full_finetune_results.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PKAqQZzVCWz",
        "outputId": "51d8326e-f200-415a-b0b1-4d63f447d05e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full finetune metrics:\n",
            "accuracy: 0.9265\n",
            "f1: 0.8775309197994615\n",
            "precision: 0.8880486119900928\n",
            "recall: 0.8691991487569148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_results['exp'].append('full_finetuning')\n",
        "data_results['accuracy'].append(full_finetune_results['accuracy'])\n",
        "data_results['f1'].append(full_finetune_results['f1'])\n",
        "data_results['recall'].append(full_finetune_results['recall'])\n",
        "data_results['precision'].append(full_finetune_results['precision'])\n",
        "data_results['time_finetuning'].append(full_time)\n",
        "data_results['num_params_finetuning'].append(full_params)\n",
        "data_results['resources_used'].append(full_memory)"
      ],
      "metadata": {
        "id": "535cOYyIPSc6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7NKL8OGVPNrm",
        "outputId": "f7aea02d-2def-47a5-bb15-44452e542c90"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exp': ['baseline', 'full_finetuning'],\n",
              " 'accuracy': [0.0795, 0.9265],\n",
              " 'f1': [0.024651162790697675, 0.8775309197994615],\n",
              " 'recall': [0.16666666666666666, 0.8691991487569148],\n",
              " 'precision': [0.013309894525364139, 0.8880486119900928],\n",
              " 'time_finetuning': [None, 1048.3201813697815],\n",
              " 'num_params_finetuning': [None, 109486854],\n",
              " 'resources_used': [None, 2212633600]}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvnRT4daVMs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Режим linear probing\n",
        "\n",
        "Для кастомной головы взяла Dropout для регуляризации, два линейных слоя для лучшей обработки признаков и GeLU, тк она вроде как в оригинальном BERT используется"
      ],
      "metadata": {
        "id": "CaDxJHDwVWDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DijHJ70KdBcL"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomHead(nn.Module):\n",
        "    def __init__(self, hidden_size=768, num_labels=6):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear1 = nn.Linear(hidden_size, hidden_size//2)\n",
        "        self.linear2 = nn.Linear(hidden_size//2, num_labels)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.gelu(x)\n",
        "        return self.linear2(x)"
      ],
      "metadata": {
        "id": "0StBPs1AVYLg"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertWithCustomHead(nn.Module):\n",
        "    def __init__(self, num_labels=6):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.classifier = CustomHead(num_labels=num_labels)\n",
        "\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
        "        outputs = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            return_dict=True\n",
        "        )\n",
        "\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}"
      ],
      "metadata": {
        "id": "9Q9Ek_oBVmPg"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lin_prob = BertWithCustomHead(num_labels=6)\n",
        "model_lin_prob.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKFwn99ldnKv",
        "outputId": "8e1e0cac-3975-411d-f00a-fda704587d66"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWithCustomHead(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): CustomHead(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (linear1): Linear(in_features=768, out_features=384, bias=True)\n",
              "    (linear2): Linear(in_features=384, out_features=6, bias=True)\n",
              "    (gelu): GELU(approximate='none')\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "training_args_lin_prob = TrainingArguments(\n",
        "    output_dir=\"./peft/linear_probing\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "trainer_lin_prob = Trainer(\n",
        "    model=model_lin_prob,\n",
        "    args=training_args_lin_prob,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer_lin_prob.train()\n",
        "full_time = time.time() - start_time\n",
        "full_params = sum(p.numel() for p in model_lin_prob.parameters() if p.requires_grad)\n",
        "full_memory = torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "ykfH_O0pdvTR",
        "outputId": "09046d49-eb89-4245-8171-0e85c2abf5d9"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 06:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.516700</td>\n",
              "      <td>1.481176</td>\n",
              "      <td>0.483000</td>\n",
              "      <td>0.193693</td>\n",
              "      <td>0.159338</td>\n",
              "      <td>0.250767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.450900</td>\n",
              "      <td>1.420908</td>\n",
              "      <td>0.501500</td>\n",
              "      <td>0.203327</td>\n",
              "      <td>0.165405</td>\n",
              "      <td>0.263902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.418400</td>\n",
              "      <td>1.404785</td>\n",
              "      <td>0.502500</td>\n",
              "      <td>0.203993</td>\n",
              "      <td>0.166062</td>\n",
              "      <td>0.264839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 ... 1 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 ... 1 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 2 ... 1 1 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_lin_prob = trainer_lin_prob.predict(tokenized_datasets[\"test\"])\n",
        "lin_prob_results = compute_metrics((test_results_lin_prob.predictions, test_results_lin_prob.label_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4dnQvL63hhkd",
        "outputId": "ca2ee6c5-b2e1-45d9-a308-be323e75482e"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 1 1 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### замеряем качество"
      ],
      "metadata": {
        "id": "ByDXks-chtZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear probing metrics:\")\n",
        "print('\\n'.join(f\"{key}: {value}\" for key, value in lin_prob_results.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU_bfPaOhudH",
        "outputId": "acedde26-9fd4-4d52-8b87-39fbdc089d81"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear probing metrics:\n",
            "accuracy: 0.507\n",
            "f1: 0.2049649242707401\n",
            "precision: 0.16789501320773925\n",
            "recall: 0.2631161851929816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_results['exp'].append('lin_probing')\n",
        "data_results['accuracy'].append(lin_prob_results['accuracy'])\n",
        "data_results['f1'].append(lin_prob_results['f1'])\n",
        "data_results['recall'].append(lin_prob_results['recall'])\n",
        "data_results['precision'].append(lin_prob_results['precision'])\n",
        "data_results['time_finetuning'].append(full_time)\n",
        "data_results['num_params_finetuning'].append(full_params)\n",
        "data_results['resources_used'].append(full_memory)"
      ],
      "metadata": {
        "id": "2LQnYOkbhy9x"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJQuIKeAh5nD",
        "outputId": "65480846-0dff-4d44-963b-d93a661f20b8"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exp': ['baseline', 'full_finetuning', 'lin_probing'],\n",
              " 'accuracy': [0.0795, 0.9265, 0.507],\n",
              " 'f1': [0.024651162790697675, 0.8775309197994615, 0.2049649242707401],\n",
              " 'recall': [0.16666666666666666, 0.8691991487569148, 0.2631161851929816],\n",
              " 'precision': [0.013309894525364139, 0.8880486119900928, 0.16789501320773925],\n",
              " 'time_finetuning': [None, 1048.3201813697815, 372.8968884944916],\n",
              " 'num_params_finetuning': [None, 109486854, 297606],\n",
              " 'resources_used': [None, 2212633600, 4417774592]}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PEFT Prompt Tuning"
      ],
      "metadata": {
        "id": "TrhnzSVXh7wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "TpmfIB9VlzQp"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptTuning(torch.nn.Module):\n",
        "    def __init__(self, model, prompt_length=20):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.prompt_embeddings = torch.nn.Embedding(prompt_length, model.config.hidden_size)\n",
        "        self.prompt_embeddings.weight.data.uniform_()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        inputs_embeds = self.model.get_input_embeddings()(input_ids)\n",
        "        prompt_embeds = self.prompt_embeddings.weight.repeat(input_ids.shape[0], 1, 1)\n",
        "        inputs_embeds = torch.cat([prompt_embeds, inputs_embeds], dim=1)\n",
        "        attention_mask = torch.cat([\n",
        "            torch.ones(input_ids.shape[0], prompt_embeds.shape[1]).to(attention_mask.device),\n",
        "            attention_mask\n",
        "        ], dim=1)\n",
        "        return self.model(inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "8V13_FnKiCW9"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=6\n",
        ")\n",
        "model_prompt = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\n",
        "prompt_model = PromptTuning(model_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYuKlMXyiRri",
        "outputId": "c1466af2-b96a-44e8-b251-167621580250"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in prompt_model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in prompt_model.prompt_embeddings.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "eCocQ3sGifq5"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "training_args_prompt = TrainingArguments(\n",
        "    output_dir=\"./peft/prompt\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        ")\n",
        "\n",
        "\n",
        "trainer_prompt = Trainer(\n",
        "    model=prompt_model,\n",
        "    args=training_args_prompt,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer_prompt.train()\n",
        "prompt_time = time.time() - start_time\n",
        "prompt_params = sum(p.numel() for p in prompt_model.parameters() if p.requires_grad)\n",
        "prompt_memory = torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "iFNlxBvBihhw",
        "outputId": "9467a1dc-2a45-429e-ebe0-3587ba987302"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 14:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.717600</td>\n",
              "      <td>1.702291</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.086785</td>\n",
              "      <td>0.058667</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.712700</td>\n",
              "      <td>1.696560</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.086785</td>\n",
              "      <td>0.058667</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.705900</td>\n",
              "      <td>1.694942</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.086785</td>\n",
              "      <td>0.058667</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "стоило получше параметры подобрать, но для сравнения такие же брала"
      ],
      "metadata": {
        "id": "WFHonaHc3YS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### замеряем качество"
      ],
      "metadata": {
        "id": "s5rA-vzRjDPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_prompt = trainer_prompt.predict(tokenized_datasets[\"test\"])\n",
        "prompt_results = compute_metrics((test_results_prompt.predictions, test_results_prompt.label_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "YGvHcFIeiw8h",
        "outputId": "435329f3-bed3-4da0-84b8-ffe1734357ab"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt tuning metrics:\")\n",
        "print('\\n'.join(f\"{key}: {value}\" for key, value in prompt_results.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZiN0VICjEa9",
        "outputId": "1b4411a7-a275-4126-9fe9-0b315b507661"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt tuning metrics:\n",
            "accuracy: 0.3475\n",
            "f1: 0.08596165739022882\n",
            "precision: 0.057916666666666665\n",
            "recall: 0.16666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_results['exp'].append('prompt_tuning')\n",
        "data_results['accuracy'].append(prompt_results['accuracy'])\n",
        "data_results['f1'].append(prompt_results['f1'])\n",
        "data_results['recall'].append(prompt_results['recall'])\n",
        "data_results['precision'].append(prompt_results['precision'])\n",
        "data_results['time_finetuning'].append(prompt_time)\n",
        "data_results['num_params_finetuning'].append(prompt_params)\n",
        "data_results['resources_used'].append(prompt_memory)"
      ],
      "metadata": {
        "id": "8bK4VOaBjqfw"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LORA tuning"
      ],
      "metadata": {
        "id": "X1YxOrOUjvnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = BertConfig.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=6\n",
        ")\n",
        "model_lora = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvYD4HhojxeS",
        "outputId": "5a46cd34-1e32-4c4e-ed25-a4bdaa399d10"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=16, # дает хороший баланс качества и параметров\n",
        "    lora_alpha=32, # для сохранения масштаба обновлений\n",
        "    target_modules=[\"query\", \"value\"], # наиболее важные для задачи\n",
        "    lora_dropout=0.1, # регуляризация\n",
        "    bias=\"none\",\n",
        "    modules_to_save=[\"classifier\"],\n",
        ")\n",
        "model_lora = get_peft_model(model_lora, lora_config)\n",
        "# model_lora"
      ],
      "metadata": {
        "id": "gLiT8al0j30r"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_lora = TrainingArguments(\n",
        "    output_dir=\"./peft/lora\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=100,\n",
        "    learning_rate=2e-5,\n",
        "    label_names=[\"labels\"]\n",
        ")"
      ],
      "metadata": {
        "id": "noqpz9aHkCgr"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "trainer_lora = Trainer(\n",
        "    model=model_lora,\n",
        "    args=training_args_lora,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer_lora.train()\n",
        "lora_time = time.time() - start_time\n",
        "lora_params = sum(p.numel() for p in model_lora.parameters() if p.requires_grad)\n",
        "lora_memory = torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "lXsFAuadkAnp",
        "outputId": "a334f988-29b5-4a66-8913-49cfb0878190"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3000/3000 12:12, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.312400</td>\n",
              "      <td>1.228146</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.225906</td>\n",
              "      <td>0.187646</td>\n",
              "      <td>0.292964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.174900</td>\n",
              "      <td>1.119806</td>\n",
              "      <td>0.577000</td>\n",
              "      <td>0.237714</td>\n",
              "      <td>0.198968</td>\n",
              "      <td>0.307670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.117000</td>\n",
              "      <td>1.095488</td>\n",
              "      <td>0.580500</td>\n",
              "      <td>0.239497</td>\n",
              "      <td>0.201073</td>\n",
              "      <td>0.309593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### замеряем качество"
      ],
      "metadata": {
        "id": "IUA7zox2kpyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_lora = trainer_lora.predict(tokenized_datasets[\"test\"])\n",
        "lora_results = compute_metrics((test_results_lora.predictions, test_results_lora.label_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ryGG1r1YkcA4",
        "outputId": "9ae16a73-786e-41a2-ac81-f2afef82271a"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LORA tuning metrics:\")\n",
        "print('\\n'.join(f\"{key}: {value}\" for key, value in lora_results.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2D346PmkrMF",
        "outputId": "73fd6570-6f6b-4baa-fe8b-1600c1c51dc7"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LORA tuning metrics:\n",
            "accuracy: 0.5895\n",
            "f1: 0.24242362916258164\n",
            "precision: 0.2051268167510324\n",
            "recall: 0.30842506717517554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_results['exp'].append('lora_tuning')\n",
        "data_results['accuracy'].append(lora_results['accuracy'])\n",
        "data_results['f1'].append(lora_results['f1'])\n",
        "data_results['recall'].append(lora_results['recall'])\n",
        "data_results['precision'].append(lora_results['precision'])\n",
        "data_results['time_finetuning'].append(lora_time)\n",
        "data_results['num_params_finetuning'].append(lora_params)\n",
        "data_results['resources_used'].append(lora_memory)"
      ],
      "metadata": {
        "id": "SulBq66uk1d0"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Выводы"
      ],
      "metadata": {
        "id": "SfRrYKKU8mA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(data_results)\n",
        "df_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eYfKAuGW8m9N",
        "outputId": "29223e53-0d30-4e29-f778-170af76a5221"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               exp  accuracy        f1    recall  precision  time_finetuning  \\\n",
              "0         baseline    0.0795  0.024651  0.166667   0.013310              NaN   \n",
              "1  full_finetuning    0.9265  0.877531  0.869199   0.888049      1048.320181   \n",
              "2      lin_probing    0.5070  0.204965  0.263116   0.167895       372.896888   \n",
              "3    prompt_tuning    0.3475  0.085962  0.166667   0.057917       853.139068   \n",
              "4      lora_tuning    0.5895  0.242424  0.308425   0.205127       733.574782   \n",
              "\n",
              "   num_params_finetuning  resources_used  \n",
              "0                    NaN             NaN  \n",
              "1            109486854.0    2.212634e+09  \n",
              "2               297606.0    4.417775e+09  \n",
              "3                15360.0    4.417775e+09  \n",
              "4               594438.0    5.311043e+09  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5602ac9a-e9ff-4f0e-b135-c66dfe936a10\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exp</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>time_finetuning</th>\n",
              "      <th>num_params_finetuning</th>\n",
              "      <th>resources_used</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>baseline</td>\n",
              "      <td>0.0795</td>\n",
              "      <td>0.024651</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.013310</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>full_finetuning</td>\n",
              "      <td>0.9265</td>\n",
              "      <td>0.877531</td>\n",
              "      <td>0.869199</td>\n",
              "      <td>0.888049</td>\n",
              "      <td>1048.320181</td>\n",
              "      <td>109486854.0</td>\n",
              "      <td>2.212634e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lin_probing</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.204965</td>\n",
              "      <td>0.263116</td>\n",
              "      <td>0.167895</td>\n",
              "      <td>372.896888</td>\n",
              "      <td>297606.0</td>\n",
              "      <td>4.417775e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prompt_tuning</td>\n",
              "      <td>0.3475</td>\n",
              "      <td>0.085962</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.057917</td>\n",
              "      <td>853.139068</td>\n",
              "      <td>15360.0</td>\n",
              "      <td>4.417775e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lora_tuning</td>\n",
              "      <td>0.5895</td>\n",
              "      <td>0.242424</td>\n",
              "      <td>0.308425</td>\n",
              "      <td>0.205127</td>\n",
              "      <td>733.574782</td>\n",
              "      <td>594438.0</td>\n",
              "      <td>5.311043e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5602ac9a-e9ff-4f0e-b135-c66dfe936a10')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5602ac9a-e9ff-4f0e-b135-c66dfe936a10 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5602ac9a-e9ff-4f0e-b135-c66dfe936a10');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2fcb2627-9c5e-473c-8c14-be67873ad861\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2fcb2627-9c5e-473c-8c14-be67873ad861')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2fcb2627-9c5e-473c-8c14-be67873ad861 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"exp\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"full_finetuning\",\n          \"lora_tuning\",\n          \"lin_probing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3120648970967417,\n        \"min\": 0.0795,\n        \"max\": 0.9265,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9265,\n          0.5895,\n          0.507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34157240983546944,\n        \"min\": 0.024651162790697675,\n        \"max\": 0.8775309197994615,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8775309197994615,\n          0.24242362916258164,\n          0.2049649242707401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29408814225873736,\n        \"min\": 0.16666666666666666,\n        \"max\": 0.8691991487569148,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8691991487569148,\n          0.30842506717517554,\n          0.16666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3561686806565047,\n        \"min\": 0.013309894525364139,\n        \"max\": 0.8880486119900928,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8880486119900928,\n          0.2051268167510324,\n          0.16789501320773925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_finetuning\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 284.0735922979768,\n        \"min\": 372.8968884944916,\n        \"max\": 1048.3201813697815,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          372.8968884944916,\n          733.5747816562653,\n          1048.3201813697815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_params_finetuning\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54592704.97899682,\n        \"min\": 15360.0,\n        \"max\": 109486854.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          297606.0,\n          594438.0,\n          109486854.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"resources_used\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1320394101.4559336,\n        \"min\": 2212633600.0,\n        \"max\": 5311042560.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2212633600.0,\n          4417774592.0,\n          5311042560.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Full Fine-tuning показывает наилучшее качество, но требует больше всего ресурсов.\n",
        "- Linear Probing самый быстрый, но довольно сильно уступает по качеству full-finetuning. Точно надо дольше учиться и лучше подобрать параметры\n",
        "- Prompt tuning - показал наихудшие резлутаты, но ресурсов потребляет меньше, чем full-finetuning. Что-то среднее между LORA и full-finetuning. Требуется более тонкая настрочка длины промпта и праметров\n",
        "- LORA finetuning - что-то среднее между full-finetuning и linear probbing.Если лучше подобрать параметры, то при меньшем кол-ве ресурсов можно получить вполне хорошее качество, которое будет сравнимо с full-finetuning\n",
        "\n"
      ],
      "metadata": {
        "id": "LB9ewqKM8rWf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZfjarulXDGR1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}